#!/usr/bin/env python3
"""
command-line utility for starting/monitoring paperspace jobs
    notably can use a yaml file in cwd to specify defaults
"""

# TODO: runlocal command
# TODO: see if switches make sense (should -s and -l be reserved for short
#       and long?)
# TODO: maybe a --quiet/-q switch for some of these to reduce chattiness?


import argparse
import datetime
import sys
import time

import pspace


DEFAULT_TAIL_LINES = 20


def process_command_line(argv):
    """Process command line invocation arguments and switches.

    Args:
        argv: list of arguments, or `None` from ``sys.argv[1:]``.

    Returns:
        argparse.Namespace: named attributes of arguments and switches
    """
    #script_name = argv[0]
    argv = argv[1:]

    # initialize the parser object:
    parser = argparse.ArgumentParser(
            description="Utilities for creating and monitoring paperspace jobs.")
    subparsers = parser.add_subparsers(dest='pspace_cmd', help='sub-command help')

    # create
    parser_create = subparsers.add_parser('create', help='create a new job')
    parser_create.add_argument(
            '--command', action='store',
            help='What command to execute on remote machine.'
            )
    parser_create.add_argument(
            '--machineType', action='store',
            help='What type of remote machine to use.'
            )

    # tail (of job log file)
    parser_tail = subparsers.add_parser('tail', help='get the tail of a job\'s log')
    parser_tail.add_argument(
            'job_id', nargs='?',
            help='ID of job to be checked.'
            )
    parser_tail.add_argument(
            '-f', '--follow', action='store_true',
            help='Follow the log file until cancelled or PSEOF.'
            )
    group = parser_tail.add_mutually_exclusive_group()
    group.add_argument(
            '-l', '--last', action='store', type=int,
            help='Only show the last this many lines. (default: 20)'
            )
    group.add_argument(
            '-a', '--all', action='store_true',
            help='Show all lines of log file.'
            )

    # jobs
    parser_jobs = subparsers.add_parser('jobs', help='list jobs')
    parser_jobs.add_argument(
            '-s', '--state', action='store',
            help='Filter only jobs matching this run state.'
            )
    parser_jobs.add_argument(
            '-l', '--last', action='store', type=int,
            help='Only list the last this many jobs matching.'
            )

    # status
    parser_status = subparsers.add_parser('status', help='get a job\'s status')
    parser_status.add_argument(
            'job_id', nargs='?',
            help='ID of job to be checked.'
            )

    # getart
    parser_getart = subparsers.add_parser('getart', help='download artifact files from a job')
    parser_getart.add_argument(
            'job_id', nargs='?',
            help='ID of job to fetch artifacts for.'
            )
    parser_getart.add_argument(
            '--datadir', action='store', default='data',
            help='Local data directory holding to put job data dir.'
            )

    # stop
    parser_stop = subparsers.add_parser('stop', help='stop or cancel a job')
    parser_stop.add_argument(
            'job_id', nargs='?',
            help='ID of job to fetch artifacts for.'
            )

    args = parser.parse_args(argv)

    return args


def get_job_id(args, pspace_last):
    if args.job_id is not None:
        job_id = args.job_id
    else:
        try:
            job_id = pspace_last['job_info']['id']
        except KeyError:
            print("Can't determine job id.")
            exit(1)
    return job_id


def parse_jobinfo_dt(dt_str):
    """From dt string from job_info, return datetime in UTC
    """
    dt = datetime.datetime.strptime(
                dt_str[:-5], "%Y-%m-%dT%H:%M:%S"
                )
    return dt.replace(tzinfo=datetime.timezone.utc)


def wrap_command_str(in_str, max_width, indent):
    max_width = max_width - indent
    # wrap command list in a good way for commands (split at start of switch)
    command_list = in_str.split(' -')
    # after splitting, join as many pieces together that will fit on line
    new_command_list = []
    in_start = 0
    while in_start < len(command_list):
        in_end = in_start + 1
        while in_end <= len(command_list):
            if len(' -'.join(command_list[in_start:in_end])) < max_width:
                in_end += 1
            else:
                in_end -= 1
                in_end = max(in_start + 1, in_end)
                break
        new_command_list.append(' -'.join(command_list[in_start:in_end]))
        in_start = in_end

    command_str = ""
    for (i, command_substr) in enumerate(new_command_list):
        if i == 0:
            command_str += command_substr + "\n"
        else:
            command_str += " "*indent + "-" + command_substr + "\n"
    return command_str.rstrip()


def print_create_options(create_options):
    indent_str = " "*4
    indent = 4 + len('command:  ')

    command_str = wrap_command_str(create_options['command'], 79, indent)

    for opt in sorted(create_options):
        if opt=='command':
            opt_value = command_str
        else:
            opt_value = create_options[opt]

        print(indent_str + opt + ": " + str(opt_value))


def command_status(args):
    pspace_last = pspace.get_last_info()
    job_id = get_job_id(args, pspace_last)

    job_info = pspace.get_job_info(job_id)
    pspace.save_last_info(job_info)

    print("Job: " + job_id)
    print("State: " + job_info['state'])

    if job_info.get('dtStarted', None) is not None:
        started_utc = parse_jobinfo_dt(job_info['dtStarted'])
        started_local = started_utc.astimezone()
        print("Started: " + started_local.strftime("%Y-%m-%d %I:%M:%S%p"))

    if job_info['state'] in ['Stopped', 'Failed', 'Cancelled']:
        # get finished datetime in local time zone
        finished_utc = parse_jobinfo_dt(job_info['dtFinished'])
        finished_local = finished_utc.astimezone()
        print("Finished: " + finished_local.strftime("%Y-%m-%d %I:%M:%S%p"))
        print("Duration: " + str(finished_utc - started_utc))
    else:
        print("Duration (to now): " + str(datetime.datetime.now(datetime.timezone.utc) - started_utc))
    if job_info['state'] in ['Stopped', 'Failed']:
        print("Exit Code: {0}".format(job_info['exitCode']))


def command_jobs(args):
    kwargs = {}
    valid_states = ['Pending', 'Provisioned', 'Running', 'Stopped',
            'Error', 'Failed', 'Cancelled'
            ]
    if args.state is not None:
        # match any state argument case-insensitively, only first chars are
        #   needed
        state = args.state[0].upper() + args.state[1:]
        matching_state = [x for x in valid_states if x.startswith(state)][0]
        kwargs['state'] = matching_state

    print(kwargs)
    job_list = pspace.jobs_list(**kwargs)
    # job_list appears to be in chronological order (first is earliest)
    if args.last is not None:
        job_list = job_list[-args.last:]

    print_keys = ['name', 'state', 'entrypoint', 'project', 'dtStarted',
            'dtFinished', 'exitCode'
            ]
    for job in job_list:
        print(job['id'])
        job['entrypoint'] = wrap_command_str(job['entrypoint'], 79, 4+13)
        for key in print_keys:
            print(" "*4 + key + ": " + str(job.get(key, '')))


def command_tail(args):
    # TODO: there is a max number of lines that paperspace.jobs.logs will return
    #   (default 2000).  We must keep asking for more lines if we get maximum
    tail_lines = args.last or DEFAULT_TAIL_LINES
    if args.all:
        # tail_lines = 0 is special value that indicates show all lines
        tail_lines = 0

    pspace_last = pspace.get_last_info()
    job_id = get_job_id(args, pspace_last)

    line_start = 0
    if tail_lines != 0:
        try:
            last_tot_log_lines = pspace_last['pspace_info']['total_log_lines']
            line_start = max(0, last_tot_log_lines - tail_lines)
        except KeyError:
            pass

    job_info = pspace.get_job_info(job_id)

    print("Job: " + job_id)
    print("State: " + job_info['state'] + " "*10, end="", flush=True)
    if pspace.job_not_started(job_id, job_info) and args.follow:
        # waiting for job to start, updating state while we wait
        while pspace.job_not_started(job_id, job_info):
            time.sleep(5)
            last_state = job_info['state']
            job_info = pspace.get_job_info(job_id)
            if job_info['state'] != last_state:
                print("\r", end="", flush=True)
                print("State: " + job_info['state'] + " "*10, end="", flush=True)
    print("")

    # so we don't print log lines if the old status says something before Running
    if pspace.job_started(job_id, job_info):
        log_lines = pspace.get_log_lines(job_id, line_start=line_start)
        total_log_lines = line_start + len(log_lines)
        pspace.save_last_info(job_info, {'total_log_lines':total_log_lines})
        for line in log_lines[-tail_lines:]:
            print(line)

    if args.follow:
        end_time = None
        line_start = len(log_lines) + line_start
        last_log_line = log_lines[-1] if log_lines else ''
        while last_log_line != "PSEOF":
            job_info = pspace.get_job_info(job_id)
            if pspace.job_done(job_id, job_info):
                finished_utc = parse_jobinfo_dt(job_info['dtFinished'])
                if datetime.datetime.now(datetime.timezone.utc) - finished_utc > datetime.timedelta(seconds=20):
                    break

            time.sleep(5)

            log_lines = pspace.get_log_lines(job_id, line_start=line_start)
            line_start += len(log_lines)
            last_log_line = log_lines[-1] if log_lines else last_log_line
            for line in log_lines[-tail_lines:]:
                print(line)


def command_create(args):
    override_args = vars(args)
    override_args.pop('pspace_cmd')
    job_config = pspace.get_config('create', override_args)

    print('Submitting with options:')
    print_create_options(job_config)

    job_info = pspace.jobs_create(**job_config)
    print("Job " + job_info['id'] + " created.")

    pspace.save_last_info(job_info)


def command_getart(args):
    pspace_last = pspace.get_last_info()
    job_id = get_job_id(args, pspace_last)
    local_data_dir = args.datadir

    pspace.get_artifacts(job_id, local_data_dir)
    pspace.save_log(job_id, local_data_dir)


def command_stop(args):
    pspace_last = pspace.get_last_info()
    job_id = get_job_id(args, pspace_last)
    returnval = pspace.stop_job(job_id)
    if not returnval:
        print("Success")



def main(argv=None):
    args = process_command_line(argv)

    if args.pspace_cmd == 'create':
        command_create(args)
    elif args.pspace_cmd == 'tail':
        command_tail(args)
    elif args.pspace_cmd == 'status':
        command_status(args)
    elif args.pspace_cmd == 'jobs':
        command_jobs(args)
    elif args.pspace_cmd == 'getart':
        command_getart(args)
    elif args.pspace_cmd == 'stop':
        command_stop(args)

    return 0


if __name__ == "__main__":
    try:
        status = main(sys.argv)
    except KeyboardInterrupt:
        # Make a very clean exit (no debug info) if user breaks with Ctrl-C
        print("Stopped by Keyboard Interrupt", file=sys.stderr)
        # exit error code for Ctrl-C
        status = 130

    sys.exit(status)
