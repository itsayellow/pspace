#!/usr/bin/env python3
"""
command-line utility for starting/monitoring paperspace jobs
    notably can use a yaml file in cwd to specify defaults
"""

# TODO: Should we only make a .pspace dir if a pspace.yaml file exists?
# TODO: see if switches make sense (should -s and -l be reserved for short
#       and long?)
# TODO: maybe a --quiet/-q switch for some of these to reduce chattiness?
# TODO: always use UTC or always use local (set by switch?)


import argparse
import datetime
import pathlib
import sys
import time

import pspace
import yaml


VALID_JOB_STATES = [ 'Pending', 'Provisioned', 'Running', 'Stopped',
        'Error', 'Failed', 'Cancelled']
CMD_ARG_DEFAULTS = {
        'create':{
            'command': 'echo hello world',
            'container': 'tensorflow/tensorflow-python:latest',
            'machineType': 'K80',
            'ignoreFiles': ['ignore1', 'ignore2'],
            },
        'tail':{
            'follow': False,
            'last': 20,
            'all': False,
            },
        'jobs':{
            'project': None,
            'state': None,
            'last': None,
            },
        'getart':{
            'destdir': 'data',
            },
        }

def process_command_line(argv):
    """Process command line invocation arguments and switches.

    Args:
        argv: list of arguments, or `None` from ``sys.argv[1:]``.

    Returns:
        argparse.Namespace: named attributes of arguments and switches
    """
    #script_name = argv[0]
    argv = argv[1:]

    # initialize the parser object:
    parser = argparse.ArgumentParser(
            description="Utilities for creating and monitoring paperspace jobs.")
    subparsers = parser.add_subparsers(dest='pspace_cmd', help='sub-command help')

    # create
    parser_create = subparsers.add_parser('create', help='create a new job')
    parser_create.add_argument(
            '--command', action='store',
            help='What command to execute on remote machine.'
            )
    parser_create.add_argument(
            '--machineType', action='store',
            help='What type of remote machine to use.'
            )
    parser_create.add_argument(
            '--project', action='store',
            help='The Paperspace project for the job.'
            )
    parser_create.add_argument(
            '--ignoreFiles', action='store',
            help='The directories or files to ignore (comma-separated).'
            )
    parser_create.add_argument(
            '--container', action='store',
            help='The docker container to use.'
            )

    # tail (of job log file)
    parser_tail = subparsers.add_parser('tail', help='get the tail of a job\'s log')
    parser_tail.add_argument(
            'job_id', nargs='?',
            help='ID of job to be checked.'
            )
    parser_tail.add_argument(
            '-f', '--follow', action='store_true',
            help='Follow the log file until cancelled or PSEOF.'
            )
    group = parser_tail.add_mutually_exclusive_group()
    group.add_argument(
            '-l', '--last', action='store', type=int,
            help='Only show the last this many lines. (default: 20)'
            )
    group.add_argument(
            '-a', '--all', action='store_true',
            help='Show all lines of log file.'
            )

    # jobs
    parser_jobs = subparsers.add_parser('jobs', help='list jobs')
    parser_jobs.add_argument(
            '-p', '--project', action='store',
            help='Filter only jobs matching this project.'
            )
    parser_jobs.add_argument(
            '-s', '--state', action='store',
            help='Filter only jobs matching this run state.'
            )
    parser_jobs.add_argument(
            '-l', '--last', action='store', type=int,
            help='Only list the last this many jobs matching.'
            )

    # status
    parser_status = subparsers.add_parser('status', help='get a job\'s status')
    parser_status.add_argument(
            'job_id', nargs='?',
            help='ID of job to be checked.'
            )

    # getart
    parser_getart = subparsers.add_parser('getart', help='download artifact files from a job')
    parser_getart.add_argument(
            'job_id', nargs='?',
            help='ID of job to fetch artifacts for.'
            )
    parser_getart.add_argument(
            '--destdir', action='store',
            help='Local data directory to put job data dir. (default: data)'
            )

    # stop
    parser_stop = subparsers.add_parser('stop', help='stop or cancel a job')
    parser_stop.add_argument(
            'job_id', nargs='?',
            help='ID of job to stop.'
            )

    # newyaml
    parser_stop = subparsers.add_parser('newyaml', help='create new yaml config file from defaults')

    args = parser.parse_args(argv)

    return args


def parse_jobinfo_dt(dt_in_str, utc=False):
    """From dt string from job_info, return datetime in UTC
    """
    dt = datetime.datetime.strptime(
                dt_in_str[:-5], "%Y-%m-%dT%H:%M:%S"
                )
    dt_utc = dt.replace(tzinfo=datetime.timezone.utc)

    if utc:
        dt_out_str = dt_utc.strftime("%Y-%m-%d %I:%M:%S%p")
    else:
        dt_local = dt_utc.astimezone()
        dt_out_str = dt_local.strftime("%Y-%m-%d %I:%M:%S%p")

    return (dt_utc, dt_out_str)


def wrap_command_str(in_str, max_width, indent):
    max_width = max_width - indent
    # wrap command list in a good way for commands (split at start of switch)
    command_list = in_str.split(' -')
    # after splitting, join as many pieces together that will fit on line
    new_command_list = []
    in_start = 0
    while in_start < len(command_list):
        in_end = in_start + 1
        while in_end <= len(command_list):
            if len(' -'.join(command_list[in_start:in_end])) < max_width:
                in_end += 1
            else:
                in_end -= 1
                in_end = max(in_start + 1, in_end)
                break
        new_command_list.append(' -'.join(command_list[in_start:in_end]))
        in_start = in_end

    command_str = ""
    for (i, command_substr) in enumerate(new_command_list):
        if i == 0:
            command_str += command_substr + "\n"
        else:
            command_str += " "*indent + "-" + command_substr + "\n"
    return command_str.rstrip()


def print_create_options(create_options):
    indent_str = " "*4
    indent = 4 + len('command:  ')

    command_str = wrap_command_str(create_options['command'], 79, indent)

    for opt in sorted(create_options):
        if opt=='command':
            opt_value = command_str
        else:
            opt_value = create_options[opt]

        print(indent_str + opt + ": " + str(opt_value))


def get_cmd_config(args, extra_keys=None):
    if extra_keys is None:
        extra_keys = []

    # Lowest Priority
    # ----------------
    # command defaults
    # pspace last info
    # yaml config
    # command arguments
    # ----------------
    # Highest Priority

    args_to_pspacelast = {
            'job_id': ('job_info', 'id'),
            'total_log_lines': ('pspace_info', 'total_log_lines'),
            }

    args_dict = vars(args)
    cmd = args_dict.pop('pspace_cmd')
    yaml_config = pspace.get_yaml_config(cmd)
    pspace_last = pspace.get_last_info()
    cmd_config = {}
    for argkey in list(args_dict.keys()) + extra_keys:
        # Default
        cmd_config[argkey] = CMD_ARG_DEFAULTS.get(cmd, {}).get(argkey, None) 

        # last command
        if argkey in args_to_pspacelast:
            (psection, pkey) = args_to_pspacelast[argkey]
            try:
                cmd_config[argkey] = pspace_last[psection][pkey]
            except KeyError:
                pass

        # YAML
        if argkey in yaml_config:
            cmd_config[argkey] = yaml_config[argkey]

        # command arguments
        if argkey in args_dict:
            if args_dict[argkey] is not None:
                cmd_config[argkey] = args_dict[argkey]

    return cmd_config


def update_job_info(job_info, utc=False):
    """Format job_info values and add new derived ones.
    """
    if job_info.get('dtStarted', None) is not None:
        (started_utc, job_info['Started']) = parse_jobinfo_dt(job_info['dtStarted'], utc=utc)
    if job_info.get('dtFinished', None) is not None:
        (finished_utc, job_info['Finished']) = parse_jobinfo_dt(job_info['dtFinished'], utc=utc)
    if 'Started' in job_info and 'Finished' in job_info:
        job_info['Duration'] = str(finished_utc - started_utc)
    elif job_info['state'] in ['Running',]:
        job_info['Duration'] = str(datetime.datetime.now(tz=datetime.timezone.utc) - started_utc) + " (to now)"
    job_info['entrypoint'] = wrap_command_str(job_info['entrypoint'], 79, 4+13)

    return job_info


def print_job_status(job_info, print_keys, utc=False):
    job_info = update_job_info(job_info, utc=utc)

    print(job_info['id'])
    max_key_len = max([len(x) for x in print_keys])
    for key in print_keys:
        post_key = " "*(max_key_len - len(key))
        print(" "*3 + key + post_key + ": " + str(job_info.get(key, '')))


def print_error(job_info):
    job_err = job_info['error']
    print("ERROR {0}: {1}".format(job_err['status'], job_err['message']))


# commands -------------------------------------------------------------------

def command_newyaml(args):
    yaml_path = pathlib.Path('pspace.yaml')
    if yaml_path.exists():
        yaml_path.rename('pspace.yaml.bak')
    with yaml_path.open('w') as yaml_fh:
        yaml.dump(CMD_ARG_DEFAULTS, yaml_fh, width=70, indent=4, sort_keys=True)


def command_status(args):
    cmd_config = get_cmd_config(args)
    job_id = cmd_config['job_id']
    if job_id is None:
        print("Cannot determine job id.")
        return

    job_info = pspace.get_job_info(job_id)
    if 'error' in job_info:
        print_error(job_info)
        return

    pspace.save_last_info(job_info)

    print_keys = ['state', 'Started', 'Finished', 'Duration', 'exitCode']
    print_job_status(job_info, print_keys, utc=False)


def command_jobs(args):
    cmd_config = get_cmd_config(args)

    if cmd_config['state'] is not None:
        # match any state argument case-insensitively, only first chars are
        #   needed
        state = cmd_config['state'][0].upper() + cmd_config['state'][1:]
        matching_state = [x for x in VALID_JOB_STATES if x.startswith(state)][0]
        cmd_config['state'] = matching_state

    list_kwargs = cmd_config.copy()
    list_kwargs.pop('last')
    job_list = pspace.jobs_list(**list_kwargs)
    # job_list appears to be in chronological order (first is earliest)
    if cmd_config['last'] is not None:
        job_list = job_list[-cmd_config['last']:]

    print_keys = ['name', 'state', 'entrypoint', 'project', 'Started',
            'Finished', 'exitCode', 'machineType',]
    first = True
    for job in job_list:
        if not first:
            print("")
        print_job_status(job, print_keys, utc=False)
        first = False


# TODO: command_tail really needs to be cleaned up!
def command_tail(args):
    cmd_config = get_cmd_config(args, ['total_log_lines'])

    # --all takes precedence over --last (also so default of last doesn't
    #   interfere with arg --all)
    if cmd_config['all']:
        cmd_config['last'] = None

    # TODO: there is a max number of lines that paperspace.jobs.logs will return
    #   (default 2000).  We must keep asking for more lines if we get maximum
    tail_lines = cmd_config['last']
    if cmd_config['all']:
        # tail_lines = 0 is special value that indicates show all lines
        tail_lines = 0

    job_id = cmd_config['job_id']

    line_start = 0
    if tail_lines != 0:
        last_tot_log_lines = cmd_config['total_log_lines']
        if last_tot_log_lines is not None:
            line_start = max(0, last_tot_log_lines - tail_lines)

    job_info = pspace.get_job_info(job_id)
    if 'error' in job_info:
        print_error(job_info)
        return

    print("Job: " + job_id)
    print("State: " + job_info['state'] + " "*10, end="", flush=True)
    if cmd_config['follow'] and pspace.job_not_started(job_id, job_info):
        # waiting for job to start, updating state while we wait
        while pspace.job_not_started(job_id, job_info):
            time.sleep(5)
            last_state = job_info['state']
            job_info = pspace.get_job_info(job_id)
            if job_info['state'] != last_state:
                print("\r", end="", flush=True)
                print("State: " + job_info['state'] + " "*10, end="", flush=True)
    print("")

    # so we don't print log lines if the old status says something before Running
    if pspace.job_started(job_id, job_info):
        log_lines = pspace.get_log_lines(job_id, line_start=line_start)
        total_log_lines = line_start + len(log_lines)
        for line in log_lines[-tail_lines:]:
            print(line)

    if cmd_config['follow']:
        end_time = None
        line_start = len(log_lines) + line_start
        last_log_line = log_lines[-1] if log_lines else ''
        while last_log_line != "PSEOF":
            job_info = pspace.get_job_info(job_id)
            if pspace.job_done(job_id, job_info):
                finished_utc = parse_jobinfo_dt(job_info['dtFinished'])
                if datetime.datetime.now(datetime.timezone.utc) - finished_utc > datetime.timedelta(seconds=20):
                    break

            time.sleep(5)

            log_lines = pspace.get_log_lines(job_id, line_start=line_start)
            line_start += len(log_lines)
            last_log_line = log_lines[-1] if log_lines else last_log_line
            for line in log_lines[-tail_lines:]:
                print(line)

    pspace.save_last_info(job_info, {'total_log_lines':total_log_lines})


def command_create(args):
    cmd_config = get_cmd_config(args)

    # TODO: figure out project cwd value if project is None here
    print('Submitting with options:')
    print_create_options(cmd_config)

    job_info = pspace.jobs_create(**cmd_config)
    if 'error' in job_info:
        print_error(job_info)
        return
    else:
        print("Job " + job_info['id'] + " created.")

    pspace.save_last_info(job_info)


def command_getart(args):
    cmd_config = get_cmd_config(args)

    print("Retrieving artifacts for job " + cmd_config['job_id'] + " ...")
    pspace.get_artifacts(cmd_config['job_id'], cmd_config['destdir'])
    # TODO: error handling
    pspace.save_log(cmd_config['job_id'], cmd_config['destdir'])


def command_stop(args):
    cmd_config = get_cmd_config(args)

    print("Stopping job " + cmd_config['job_id'] + " ...")
    returnval = pspace.stop_job(cmd_config['job_id'])
    if not returnval:
        print("Success")
    else:
        print_error(returnval)


def main(argv=None):
    args = process_command_line(argv)

    if args.pspace_cmd == 'create':
        command_create(args)
    elif args.pspace_cmd == 'tail':
        command_tail(args)
    elif args.pspace_cmd == 'status':
        command_status(args)
    elif args.pspace_cmd == 'jobs':
        command_jobs(args)
    elif args.pspace_cmd == 'getart':
        command_getart(args)
    elif args.pspace_cmd == 'stop':
        command_stop(args)
    elif args.pspace_cmd == 'newyaml':
        command_newyaml(args)

    return 0


if __name__ == "__main__":
    try:
        status = main(sys.argv)
    except KeyboardInterrupt:
        # Make a very clean exit (no debug info) if user breaks with Ctrl-C
        print("Stopped by Keyboard Interrupt", file=sys.stderr)
        # exit error code for Ctrl-C
        status = 130

    sys.exit(status)
