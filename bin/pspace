#!/usr/bin/env python3
"""
command-line utility for starting/monitoring paperspace jobs
    notably can use a yaml file in cwd to specify defaults
"""

# TODO: Should we only make a .pspace dir if a pspace.yaml file exists?
# TODO: see if switches make sense (should -s and -l be reserved for short
#       and long?)
# TODO: maybe a --quiet/-q switch for some of these to reduce chattiness?
# TODO: always use UTC or always use local (set by switch?)


import argparse
import datetime
import pathlib
import sys
import time

import pspace
import yaml


VALID_JOB_STATES = [ 'Pending', 'Provisioned', 'Running', 'Stopped',
        'Error', 'Failed', 'Cancelled']

def process_command_line(argv):
    """Process command line invocation arguments and switches.

    Args:
        argv: list of arguments, or `None` from ``sys.argv[1:]``.

    Returns:
        argparse.Namespace: named attributes of arguments and switches
    """
    #script_name = argv[0]
    argv = argv[1:]

    # initialize the parser object:
    parser = argparse.ArgumentParser(
            description="Utilities for creating and monitoring paperspace jobs.")
    subparsers = parser.add_subparsers(dest='pspace_cmd', help='sub-command help')

    # create
    parser_create = subparsers.add_parser('create', help='create a new job')
    parser_create.add_argument(
            '--command', action='store',
            help='What command to execute on remote machine.'
            )
    parser_create.add_argument(
            '--machineType', action='store',
            help='What type of remote machine to use.'
            )
    parser_create.add_argument(
            '--project', action='store',
            help='The Paperspace project for the job.'
            )
    parser_create.add_argument(
            '--ignoreFiles', action='store',
            help='The directories or files to ignore (comma-separated).'
            )
    parser_create.add_argument(
            '--container', action='store',
            help='The docker container to use.'
            )

    # tail (of job log file)
    parser_tail = subparsers.add_parser('tail', help='get the tail of a job\'s log')
    parser_tail.add_argument(
            'job_id', nargs='?',
            help='ID of job to be checked.'
            )
    parser_tail.add_argument(
            '-f', '--follow', action='store_true',
            help='Follow the log file until cancelled or PSEOF.'
            )
    group = parser_tail.add_mutually_exclusive_group()
    group.add_argument(
            '-l', '--last', action='store', type=int,
            help='Only show the last this many lines. (default: 20)'
            )
    group.add_argument(
            '-a', '--all', action='store_true',
            help='Show all lines of log file.'
            )

    # jobs
    parser_jobs = subparsers.add_parser('jobs', help='list jobs')
    parser_jobs.add_argument(
            '-p', '--project', action='store',
            help='Filter only jobs matching this project.'
            )
    parser_jobs.add_argument(
            '-s', '--state', action='store',
            help='Filter only jobs matching this run state.'
            )
    parser_jobs.add_argument(
            '-l', '--last', action='store', type=int,
            help='Only list the last this many jobs matching.'
            )

    # status
    parser_status = subparsers.add_parser('status', help='get a job\'s status')
    parser_status.add_argument(
            'job_id', nargs='?',
            help='ID of job to be checked.'
            )

    # getart
    parser_getart = subparsers.add_parser('getart', help='download artifact files from a job')
    parser_getart.add_argument(
            'job_id', nargs='?',
            help='ID of job to fetch artifacts for.'
            )
    parser_getart.add_argument(
            '--destdir', action='store',
            help='Local data directory to put job data dir. (default: data)'
            )

    # stop
    parser_stop = subparsers.add_parser('stop', help='stop or cancel a job')
    parser_stop.add_argument(
            'job_id', nargs='?',
            help='ID of job to stop.'
            )

    # newyaml
    parser_stop = subparsers.add_parser('newyaml', help='create new yaml config file from defaults')

    args = parser.parse_args(argv)

    return args


# commands -------------------------------------------------------------------

def command_newyaml(args):
    yaml_path = pathlib.Path('pspace.yaml')
    if yaml_path.exists():
        yaml_path.rename('pspace.yaml.bak')
    with yaml_path.open('w') as yaml_fh:
        yaml.dump(pspace.CMD_ARG_DEFAULTS, yaml_fh, width=70, indent=4, sort_keys=True)


def command_status(args):
    cmd_config = pspace.get_cmd_config(args)
    job_id = cmd_config['job_id']
    if job_id is None:
        print("Cannot determine job id.")
        return

    job_info = pspace.get_job_info(job_id)
    if 'error' in job_info:
        pspace.print_error(job_info)
        return

    pspace.save_last_info(job_info)

    print_keys = ['state', 'Started', 'Finished', 'Duration', 'exitCode']
    pspace.print_job_status(job_info, print_keys, utc_str=False)


def command_jobs(args):
    cmd_config = pspace.get_cmd_config(args)

    if cmd_config['state'] is not None:
        # match any state argument case-insensitively, only first chars are
        #   needed
        state = cmd_config['state'][0].upper() + cmd_config['state'][1:]
        matching_state = [x for x in VALID_JOB_STATES if x.startswith(state)][0]
        cmd_config['state'] = matching_state

    list_kwargs = cmd_config.copy()
    list_kwargs.pop('last')
    job_list = pspace.jobs_list(**list_kwargs)
    # job_list appears to be in chronological order (first is earliest)
    if cmd_config['last'] is not None:
        job_list = job_list[-cmd_config['last']:]

    print_keys = ['name', 'state', 'entrypoint', 'project', 'Started',
            'Finished', 'exitCode', 'machineType',]
    first = True
    for job in job_list:
        if not first:
            print("")
        pspace.print_job_status(job, print_keys, utc_str=False)
        first = False


def command_tail(args):
    cmd_config = pspace.get_cmd_config(args, ['total_log_lines', 'last_job_id'])

    # --all takes precedence over --last (also so default of last doesn't
    #   interfere with arg --all)
    if cmd_config['all']:
        cmd_config['last'] = None

    tail_lines = cmd_config['last']
    if cmd_config['all']:
        # tail_lines = 0 is special value that indicates show all lines
        tail_lines = 0

    job_id = cmd_config['job_id']
    if job_id is None:
        print("Cannot determine job id.")
        return

    line_start = 0
    if tail_lines != 0:
        if (cmd_config['total_log_lines'] is not None) and (cmd_config['last_job_id'] == job_id):
            line_start = max(0, cmd_config['total_log_lines'] - tail_lines)

    (job_info, total_log_lines) = pspace.print_last_log_lines(
            job_id,
            tail_lines,
            line_start,
            follow=cmd_config['follow']
            )
    if job_info is not None:
        extra_save_info = {
                'total_log_lines':total_log_lines,
                'last_job_id':job_id,
                }
        pspace.save_last_info(job_info, extra_save_info)


def command_create(args):
    cmd_config = pspace.get_cmd_config(args)

    if cmd_config['project'] is None:
        cmd_config['project'] = pathlib.Path.cwd().name

    print('Submitting with options:')
    print_create_options(cmd_config)

    job_info = pspace.jobs_create(**cmd_config)
    if 'error' in job_info:
        pspace.print_error(job_info)
        return
    else:
        print("Job " + job_info['id'] + " created.")

    pspace.save_last_info(job_info)


def command_getart(args):
    cmd_config = pspace.get_cmd_config(args)

    print("Retrieving artifacts for job " + cmd_config['job_id'] + " ...")
    pspace.get_artifacts(cmd_config['job_id'], cmd_config['destdir'])
    # TODO: error handling
    pspace.save_log(cmd_config['job_id'], cmd_config['destdir'])


def command_stop(args):
    cmd_config = pspace.get_cmd_config(args)

    print("Stopping job " + cmd_config['job_id'] + " ...")
    returnval = pspace.stop_job(cmd_config['job_id'])
    if not returnval:
        print("Success")
    else:
        pspace.print_error(returnval)


def main(argv=None):
    args = process_command_line(argv)

    if args.pspace_cmd == 'create':
        command_create(args)
    elif args.pspace_cmd == 'tail':
        command_tail(args)
    elif args.pspace_cmd == 'status':
        command_status(args)
    elif args.pspace_cmd == 'jobs':
        command_jobs(args)
    elif args.pspace_cmd == 'getart':
        command_getart(args)
    elif args.pspace_cmd == 'stop':
        command_stop(args)
    elif args.pspace_cmd == 'newyaml':
        command_newyaml(args)

    return 0


if __name__ == "__main__":
    try:
        status = main(sys.argv)
    except KeyboardInterrupt:
        # Make a very clean exit (no debug info) if user breaks with Ctrl-C
        print("Stopped by Keyboard Interrupt", file=sys.stderr)
        # exit error code for Ctrl-C
        status = 130

    sys.exit(status)
